{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "454fc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from TTS.api import TTS\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf09ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(file_name=\"input_voice_01.wav\",duration=5,fs=16000):\n",
    "    print(f\"🎙️ Recording for {duration} seconds...\")\n",
    "    audio_data = sd.rec(int(fs*duration),channels=1,samplerate=fs,dtype='int16')\n",
    "    sd.wait()\n",
    "    write(file_name,fs,audio_data)\n",
    "    print(f\"✅ Recording saved to: {file_name}\")\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed28d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    print(\"🧠 Transcribing with Whisper...\")\n",
    "    model = whisper.load_model(\"medium\")\n",
    "    result = model.transcribe(file_path)\n",
    "    print(\"📝 Transcribed Text:\", result[\"text\"])\n",
    "    return result[\"text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534e3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 Microphone Array (Intel® Smart , MME (4 in, 0 out)\n",
      "   2 Headset (soundcore H30i), MME (1 in, 0 out)\n",
      "   3 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  4 Headphones (soundcore H30i), MME (0 in, 2 out)\n",
      "   5 Speaker (Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   6 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   7 Microphone Array (Intel® Smart Sound Technology for Digital Microphones), Windows DirectSound (4 in, 0 out)\n",
      "   8 Headset (soundcore H30i), Windows DirectSound (1 in, 0 out)\n",
      "   9 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "  10 Headphones (soundcore H30i), Windows DirectSound (0 in, 2 out)\n",
      "  11 Speaker (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "  12 Headphones (soundcore H30i), Windows WASAPI (0 in, 2 out)\n",
      "  13 Speaker (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  14 Headset (soundcore H30i), Windows WASAPI (1 in, 0 out)\n",
      "  15 Microphone Array (Intel® Smart Sound Technology for Digital Microphones), Windows WASAPI (2 in, 0 out)\n",
      "  16 Headphones 1 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  17 Headphones 2 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  18 PC Speaker (Realtek HD Audio 2nd output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  19 Microphone (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  20 Speakers 1 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  21 Speakers 2 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  22 PC Speaker (Realtek HD Audio output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  23 Stereo Mix (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  24 Input (), Windows WDM-KS (2 in, 0 out)\n",
      "  25 Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Abhinav S's A54)), Windows WDM-KS (0 in, 1 out)\n",
      "  26 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Abhinav S's A54)), Windows WDM-KS (1 in, 0 out)\n",
      "  27 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(soundcore H30i)), Windows WDM-KS (0 in, 1 out)\n",
      "  28 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(soundcore H30i)), Windows WDM-KS (1 in, 0 out)\n",
      "  29 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  30 Microphone Array 1 (), Windows WDM-KS (2 in, 0 out)\n",
      "  31 Microphone Array 2 (), Windows WDM-KS (2 in, 0 out)\n",
      "  32 Microphone Array 3 (), Windows WDM-KS (4 in, 0 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d84d892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ Recording for 10 seconds...\n",
      "✅ Recording saved to: input_voice_01.wav\n",
      "🧠 Transcribing with Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\TTS\\lib\\site-packages\\whisper\\model.py:124: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  a = scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Transcribed Text:  Hello Myself Abhinav Sinha, I am a student from LVU. I am doing a project on BTS whisper using a chatbot to retrieve information.\n"
     ]
    }
   ],
   "source": [
    "path = record_audio(duration=10)\n",
    "text = transcribe_audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ba6914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello Myself Abhinav Sinha, I am a student from LVU. I am doing a project on BTS whisper using a chatbot to retrieve information.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aab5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female-en-5', 'female-en-5\\n', 'female-pt-4\\n', 'male-en-2', 'male-en-2\\n', 'male-pt-3\\n']\n"
     ]
    }
   ],
   "source": [
    "print(tts.speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d7698f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\TTS\\lib\\site-packages\\TTS\\api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
      "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n",
      "g:\\TTS\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "['Why did you do that?!', \"This isn't fair!\"]\n",
      " > Processing time: 0.22624826431274414\n",
      " > Real-time factor: 0.0672957359645283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_voice_01.wav'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", gpu=True)\n",
    "tts.tts_to_file(text=\"Why did you do that?! This isn't fair!\",speaker=\"male-pt-3\\n\",language=\"en\",file_path=\"output_voice_01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84887704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95976e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
